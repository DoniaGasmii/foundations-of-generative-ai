{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"background-color:#FFFFFF\">   \n",
    "  <tr>     \n",
    "  <td><img src=\"https://upload.wikimedia.org/wikipedia/commons/9/95/Logo_EPFL_2019.svg\" width=\"150x\"/>\n",
    "  </td>     \n",
    "  <td>\n",
    "  <h1> <b>CS-461: Foundation Models and Generative AI</b> </h1>\n",
    "  Prof. Charlotte Bunne  \n",
    "  </td>   \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# ðŸ“š  Exercise Session (Coding Part) - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will implement, explore and compare three self-supervised training frameworks.\n",
    "\n",
    "1. **SimCLR (2020)** ([Link to paper](https://arxiv.org/pdf/2002.05709))\n",
    "\n",
    "2. **BYOL - Bootstrap your own latent (2020)** ([Link to paper](https://arxiv.org/pdf/2006.07733))\n",
    "\n",
    "3. **Barlow Twins (2021)** ([Link to paper](https://arxiv.org/pdf/2103.03230))\n",
    "\n",
    "Each of these has introduced important contributions shaping current state-of-the-art self-supervised learning frameworks such as DinoV2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import v2 as T\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as skm\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datasets & Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will work with the **CIFAR10 dataset**, consisting of 60,000 32x32 color images in 10 classes, with 6,000 images per class.\\\n",
    "There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "Let's download/load it and define a default transformation turning a PIL Image into a `torch.tensor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "train = CIFAR10('./data', train=True, download=True, transform=default_transform)\n",
    "test = CIFAR10('./data', train=False, download=True, transform=default_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the a few examples. \n",
    "\n",
    "#### Task: Visualization\n",
    "Complete the following code cell to visualize the first 9 images in a 3x3 grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(3,3), axes_pad=0.2)\n",
    "\n",
    "for ax, img in zip(grid, train):\n",
    "    ax.imshow(img[0].permute(1,2,0))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge in self-supervised training is that the training losses typically do not directly correspond to the model's downstream performance on an actual task of interest, e.g., image classification.\n",
    "\n",
    "Therefore, we next implement a simple evaluation pipeline, which we will later use to monitor our training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Evaluation Tools\n",
    "Complete the following function `extract_features_and_labels` which encodes all samples provided by the dataloader. If `normalize` is `True` it should additionally L2-normalize each feature vector.\n",
    "\n",
    "**Caution:** The `forward` pass of our models will later return either a batch of feature vectors of shape `(B,D)` or a `list/tuple`, with the list of features vectors being the first element. Make sure to account for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(model, dataloader, normalize=False):\n",
    "    \"\"\"\n",
    "    Extract features and labels from a dataloader using the given model.\n",
    "    model: an encoder model taking as input a batch of images (batch_size, channels, height, width) and outputing either a batch of feature vectors (batch_size, feature_dim) or a list/tuple in which the first element is the batch of feature vectors (batch_size, feature_dim)\n",
    "    dataloader: a PyTorch dataloader providing batches of (images, labels)\n",
    "    returns: features (num_samples, feature_dim), labels (num_samples,)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for batch in tqdm(dataloader, disable=True):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            feat = model(x)\n",
    "            if type(feat) is tuple or type(feat) is list:\n",
    "                repr = feat[0]\n",
    "                feat = repr\n",
    "        features.append(feat.cpu())\n",
    "        labels.append(y)\n",
    "\n",
    "    features = torch.cat(features, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    if normalize:\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a classification task at hand, two established routines to evaluate the quality of representations are **Neigheast Neighbour Probes** and **Linear Probes**, in which either a KNN classifier or a logistic regression model is trained and evaluated.\n",
    "\n",
    "Implement such probes in the following functions `run_knn_probe` and `run_linear_probe`. These functions should return the achieved test accuracy. Feel free to use tools from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn_probe(train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    Runs a k-NN probe on the given features and labels.\n",
    "    train_features: (num_train_samples, feature_dim)\n",
    "    train_labels: (num_train_samples,)\n",
    "    test_features: (num_test_samples, feature_dim)\n",
    "    test_labels: (num_test_samples,)\n",
    "    returns: accuracy (float)\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "    knn.fit(train_features, train_labels)\n",
    "    test_preds = knn.predict(test_features)\n",
    "    accuracy = skm.accuracy_score(test_labels, test_preds)\n",
    "    return accuracy\n",
    "\n",
    "def run_linear_probe(train_features, train_labels, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    Runs a linear probe on the given features and labels.\n",
    "    train_features: (num_train_samples, feature_dim)\n",
    "    train_labels: (num_train_samples,)\n",
    "    test_features: (num_test_samples, feature_dim)\n",
    "    test_labels: (num_test_samples,)\n",
    "    returns: accuracy (float)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    logreg = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "    logreg.fit(train_features, train_labels)\n",
    "    test_preds = logreg.predict(test_features)\n",
    "    accuracy = skm.accuracy_score(test_labels, test_preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our evaluation pipeline on a randomly initalized ResNet18 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=None)\n",
    "model.fc = nn.Identity()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=256, shuffle=True, num_workers=10)\n",
    "test_dataloader = DataLoader(test, batch_size=256, shuffle=False, num_workers=10)\n",
    "\n",
    "train_features, train_labels = extract_features_and_labels(model, train_dataloader)\n",
    "test_features, test_labels = extract_features_and_labels(model, test_dataloader)\n",
    "\n",
    "knn_accuracy = run_knn_probe(train_features.numpy(), train_labels.numpy(), test_features.numpy(), test_labels.numpy())\n",
    "linear_accuracy = run_linear_probe(train_features.numpy(), train_labels.numpy(), test_features.numpy(), test_labels.numpy())\n",
    "\n",
    "print(f'k-NN accuracy: {knn_accuracy*100:.2f}%')\n",
    "print(f'Linear probe accuracy: {linear_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we observe that even the representations of a randomly initalized ResNet18 achieve already accuracies far beyond random performance. Keep this observation in mind for later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start again by implementing **SimCLR** (Simple Framework for Contrastive Learning of Visual Representations), a self-supervised learning method for training deep visual representations without labeled data.\\\n",
    "If you have already sucessfully implemented and trained the SimCLR model in the Exercise Session 1 (Task 3), feel free to skip the implementation part of this section and load your model from last week for the evaluation.\n",
    "\n",
    "SimCLR is based on the idea of contrastive learning, i.e., the key idea to learn representations by maximizing agreement between differently augmented views of the same image (termed positive pairs) while minimizing agreement between pairs of views of different images (termed negative pairs).  \n",
    "\n",
    "**Main components:**\n",
    "1. **Data Augmentation:** Generate two correlated views of the same image (e.g., random crop, color distortion, Gaussian blur).  \n",
    "2. **Encoder Network:** A deep neural network (commonly ResNet) extracts feature representations from each view.  \n",
    "3. **Projection Head:** A small MLP maps the representations into a latent space where contrastive loss is applied.  \n",
    "4. **Contrastive Loss (NT-Xent):** Encourages representations of augmented views of the same image to be close, while pushing apart those of different images.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentations\n",
    "\n",
    "A key contribution of the SimCLR paper was its systematic study and ablation of image augmentations for contrastive learning. Based on these findings, the SimCLR framework applies the following transformations: random cropping and resizing, horizontal flips, color distortions, grayscale conversion, and Gaussian blur.\n",
    "\n",
    "We implement these transformations in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLRTransform:\n",
    "\n",
    "    def __init__(self, size=32, s=0.5, blur_p=0.5):\n",
    "        color_jitter = T.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "        k = 3 if size <= 32 else 5\n",
    "        base = [\n",
    "            T.RandomResizedCrop(size=size, scale=(0.2, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply([color_jitter], p=0.8),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomApply([T.GaussianBlur(kernel_size=k, sigma=(0.1, 2.0))], p=blur_p),\n",
    "            T.ToTensor()\n",
    "        ]\n",
    "        self.train_transform = T.Compose(base)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.train_transform(x), self.train_transform(x)\n",
    "\n",
    "def simclr_collate_fn(batch):\n",
    "    xs1, xs2, ys = [], [], []\n",
    "    for (x1, x2), y in batch:\n",
    "        xs1.append(x1)\n",
    "        xs2.append(x2)\n",
    "        ys.append(y)\n",
    "    return torch.stack(xs1), torch.stack(xs2), torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: SimCLR Model Architecture\n",
    "\n",
    "In SimCLR, the model architecture consists of two stacked components:  \n",
    "1. An encoder $f(\\cdot)$, e.g., a CNN, that yields the image representation.  \n",
    "2. A projector head $g(\\cdot)$, e.g., an MLP, that yields projections of the image representations. These are used only during training.  \n",
    "\n",
    "Implement the `forward` pass of the architecture below. Follow the specifications in the docstring. We already provide example network layers (tested for convergence), but feel free to explore alternative (potentially better) configurations!  \n",
    "\n",
    "**Caution:** Make sure to L2-normalize the projections before returning them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLRModel(nn.Module):\n",
    "\n",
    "    def __init__(self, proj_dim=128, hidden=2048):\n",
    "        super().__init__()\n",
    "        enc = resnet18(weights=None)\n",
    "        enc.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        enc.maxpool = nn.Identity()\n",
    "        enc.fc = nn.Identity()\n",
    "        self.encoder = enc\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden, proj_dim) # (bs, proj_dim)\n",
    "        )\n",
    "\n",
    "    def normalize(self, x, eps=1e-8):\n",
    "        \"\"\"\n",
    "        Normalizes a batch of feature vectors.\n",
    "        \"\"\"\n",
    "        return x / (x.norm(dim=-1, keepdim=True) + eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, channels, height, width) tensor of images\n",
    "        returns: repr (batch_size, feature_dim), proj (batch_size, proj_dim)\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        repr = self.encoder(x)\n",
    "        proj = self.normalize(self.projector(repr))\n",
    "        return repr, proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: NT-Xent Loss\n",
    "\n",
    "As mentioned, in SimCLR training we maximize agreement between different views of the same image, while minimizing agreement between views of distinct images. For this, we use the normalized temperature-scaled cross entropy (NT-Xent) loss.\n",
    "\n",
    "Let $\\{x_i\\}_{i=1}^{N}$ be a batch of image views, with $x_{2k-1}$ and $x_{2k}$ being views of the same original image.  \n",
    "For each $i = 1, \\dots, N$, we obtain a projected representation $z_i$ as\n",
    "$$\n",
    "z_i = g(f(x_i)).\n",
    "$$\n",
    "\n",
    "For each positive pair $(i,j)$ and temperature $\\tau$, the NT-Xent loss is computed as\n",
    "$$\n",
    "\\ell_{i,j} = - \\log \\frac{\\exp\\big(\\mathrm{sim}(\\mathbf{z}_i, \\mathbf{z}_j)/\\tau\\big)}\n",
    "{\\sum_{k=1}^{2N} \\mathbf{1}_{[k \\neq i]} \\exp\\big(\\mathrm{sim}(\\mathbf{z}_i, \\mathbf{z}_k)/\\tau\\big)}\n",
    "$$\n",
    "and for a complete batch as \n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{N} \\sum_{k=1}^{N} \\ell_{2k-1,2k} + \\ell_{2k,2k-1}.\n",
    "$$\n",
    "\n",
    "Implement this loss in the following function `nt_xent`.  \n",
    "It takes as input two tensors of projected representations, `z1` and `z2`, each corresponding to different augmentations of the same batch of images; i.e., for each index `i`, the vectors `z1[i]` and `z2[i]` form a positive pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent(z1, z2, tau=0.5):\n",
    "    \"\"\"\n",
    "    Computes NT-Xent loss.\n",
    "    z1: (batch_size, feature_dim) tensor of normalized projection vectors\n",
    "    z2: (batch_size, feature_dim) tensor of normalized projection vectors\n",
    "    returns: loss (scalar)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    B, d = z1.shape\n",
    "    z = torch.cat([z1, z2], dim=0)              # (2B, d)\n",
    "    sim = (z @ z.t()) / tau                     # (2B, 2B)\n",
    "    mask = torch.eye(2*B, dtype=torch.bool, device=z.device)\n",
    "    sim.masked_fill_(mask, -1e9)\n",
    "    targets = torch.arange(B, device=z.device)\n",
    "    targets = torch.cat([targets + B, targets], dim=0)\n",
    "    return F.cross_entropy(sim, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us initialize the datasets and dataloaders. For evaluation, we prepare extra dataloaders without the SimCLR augmentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_transform = SimCLRTransform(size=32)\n",
    "\n",
    "train_ds = CIFAR10(root=\"./data\", train=True, download=True, transform=simclr_transform)\n",
    "test_ds  = CIFAR10(root=\"./data\", train=False, download=True, transform=simclr_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, num_workers=10, pin_memory=True, collate_fn=simclr_collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, num_workers=10, pin_memory=True, collate_fn=simclr_collate_fn)\n",
    "\n",
    "train_ds_noaugment = CIFAR10(root=\"./data\", train=True, download=True, transform=default_transform)\n",
    "test_ds_noaugment  = CIFAR10(root=\"./data\", train=False, download=True, transform=default_transform)\n",
    "\n",
    "train_loader_noaugment = DataLoader(train_ds_noaugment, batch_size=256, shuffle=False, num_workers=10, pin_memory=True)\n",
    "test_loader_noaugment  = DataLoader(test_ds_noaugment,  batch_size=256, shuffle=False, num_workers=10, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: SimCLR Training\n",
    "\n",
    "Now that all components are ready, it's time to put everything together.  \n",
    "\n",
    "Complete the training pipeline below and train your SimCLR model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_model = SimCLRModel(proj_dim=128).to(device)\n",
    "\n",
    "total_epochs = 50\n",
    "warmup_epochs = 10\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / float(warmup_epochs)\n",
    "    t = (epoch - warmup_epochs) / float(total_epochs - warmup_epochs)\n",
    "    return 0.0 + 0.5 * (1 - 0.0) * (1 + math.cos(math.pi * t))\n",
    "\n",
    "optimizer = torch.optim.AdamW(simclr_model.parameters(), lr=0.6, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "all_accuracies = []\n",
    "all_losses = []\n",
    "for epoch in range(total_epochs):\n",
    "    simclr_model.train()\n",
    "    avg_loss = 0.\n",
    "    for x1, x2, y in tqdm(train_loader):\n",
    "        # TODO\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "        _, proj1 = simclr_model(x1)\n",
    "        _, proj2 = simclr_model(x2)\n",
    "        loss = nt_xent(proj1, proj2, tau=0.5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    simclr_model.eval()\n",
    "    train_features, train_labels = extract_features_and_labels(simclr_model, train_loader_noaugment, normalize=True)\n",
    "    test_features, test_labels = extract_features_and_labels(simclr_model, test_loader_noaugment, normalize=True)\n",
    "    acc = run_knn_probe(train_features, train_labels, test_features, test_labels)\n",
    "    avg_loss = avg_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}, kNN Accuracy: {acc:.4f}\")\n",
    "    all_accuracies.append(acc)\n",
    "    all_losses.append(avg_loss)\n",
    "\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "torch.save(simclr_model.state_dict(), f'./checkpoints/simclr_cifar10.pth')\n",
    "print('Model saved to ./checkpoints/simclr_cifar10.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the training progress by plotting the loss and accuracy curves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(range(1, total_epochs+1), all_losses)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Average NT-Xent Loss')\n",
    "\n",
    "axes[1].plot(range(1, total_epochs+1), all_accuracies)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('k-NN Accuracy (%)')\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also run a quick linear probe for the final results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features_and_labels(simclr_model, train_loader_noaugment, normalize=True)\n",
    "test_features, test_labels = extract_features_and_labels(simclr_model, test_loader_noaugment, normalize=True)\n",
    "\n",
    "acc = run_linear_probe(train_features, train_labels, test_features, test_labels)\n",
    "print(f'Final Linear Probe Accuracy: {acc:.4f}%')\n",
    "print(f'Final k-NN Accuracy: {all_accuracies[-1]:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Shortcomings\n",
    "What are potential shortcomings and practical disadvantages of the SimCLR framework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "1. **Large Batch Size Requirement** To get enough negative samples, it typically requires very large batch sizes (e.g., 4096+), leading to high GPU demands.\n",
    "2. **Sensitive to Augmentations** The quality of learned representations depends heavily on the choice of data augmentations (e.g., color distortion, cropping). Take a look at the original paper for more information.\n",
    "3. **Inefficient Negative Sampling** SimCLR treats all negatives equally, even if some are more informative (hard negatives) than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BYOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will implement **BYOL (Bootstrap Your Own Latent)**, a self-supervised representation learning framework that takes a different approach from contrastive methods.  \n",
    "\n",
    "Recall our initial observation: even a randomly initialized CNN can produce representations that achieve non-trivial k-NN accuracy. BYOL builds on this insight.  \n",
    "\n",
    "The key idea is that a given encoder, $f_{\\text{target}}$â€”even if random or mediocreâ€”can serve as a teacher to train a stronger encoder, $f_{\\text{online}}$. The training objective is to make $f_{\\text{online}}$ imitate the outputs of $f_{\\text{target}}$ when both are fed *different augmentations of the same input image*. This process is known as *bootstrapping*.  \n",
    "\n",
    "Although BYOL still aligns representations of different views of the same image, unlike SimCLR, it is **not strictly contrastive**: it avoids the use of negative examples altogether.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same set of augmentations as in SimCLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOLTransform:\n",
    "\n",
    "    def __init__(self, size=32, s=0.5, blur_p=0.5):\n",
    "        color_jitter = T.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "        k = 3 if size <= 32 else 5\n",
    "        base = [\n",
    "            T.RandomResizedCrop(size=size, scale=(0.2, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply([color_jitter], p=0.8),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomApply([T.GaussianBlur(kernel_size=k, sigma=(0.1, 2.0))], p=blur_p),\n",
    "            T.ToTensor()\n",
    "        ]\n",
    "        self.train_transform = T.Compose(base)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.train_transform(x), self.train_transform(x)\n",
    "\n",
    "\n",
    "def byol_collate_fn(batch):\n",
    "    xs1, xs2, ys = [], [], []\n",
    "    for (x1, x2), y in batch:\n",
    "        xs1.append(x1)\n",
    "        xs2.append(x2)\n",
    "        ys.append(y)\n",
    "    return torch.stack(xs1), torch.stack(xs2), torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: BYOL Architecture\n",
    "\n",
    "The BYOL architecture builds on the SimCLR architecture but introduces a third component on top of the encoder $f(\\cdot)$ and the projector head $g(\\cdot)$: the predictor head $q(\\cdot)$.  \n",
    "\n",
    "Implement the `forward` pass of the provided `BYOLModel`. It should output three tensors:  \n",
    "1. The representations $f(x)$,  \n",
    "2. Their normalized projections $\\mathrm{normalize}(g(f(x)))$, and  \n",
    "3. The normalized predictions $\\mathrm{normalize}(q(g(f(x))))$.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOLModel(nn.Module):\n",
    "\n",
    "    def __init__(self, proj_dim=128, hidden_dim=2048):\n",
    "        super().__init__()\n",
    "        enc = resnet18(weights=None)\n",
    "        enc.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        enc.maxpool = nn.Identity()\n",
    "        enc.fc = nn.Identity()\n",
    "        self.encoder = enc\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(proj_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, channels, height, width) tensor of images\n",
    "        returns: repr (batch_size, feature_dim), proj (batch_size, proj_dim), pred (batch_size, proj_dim)\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        repr = self.encoder(x)\n",
    "        proj = self.projector(repr)\n",
    "        pred = self.predictor(proj)\n",
    "\n",
    "        proj = F.normalize(proj, dim=-1, eps=1e-8)\n",
    "        pred = F.normalize(pred, dim=-1, eps=1e-8)\n",
    "\n",
    "        return repr, proj, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initalize our datasets and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byol_transform = BYOLTransform(size=32)\n",
    "\n",
    "train_ds = CIFAR10(root=\"./data\", train=True, download=True, transform=byol_transform)\n",
    "test_ds  = CIFAR10(root=\"./data\", train=False, download=True, transform=byol_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, num_workers=10, pin_memory=True, collate_fn=byol_collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, num_workers=10, pin_memory=True, collate_fn=byol_collate_fn)\n",
    "\n",
    "train_ds_noaugment = CIFAR10(root=\"./data\", train=True, download=True, transform=default_transform)\n",
    "test_ds_noaugment  = CIFAR10(root=\"./data\", train=False, download=True, transform=default_transform)\n",
    "\n",
    "train_loader_noaugment = DataLoader(train_ds_noaugment, batch_size=256, shuffle=False, num_workers=10, pin_memory=True)\n",
    "test_loader_noaugment  = DataLoader(test_ds_noaugment,  batch_size=256, shuffle=False, num_workers=10, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our models. In BYOL, we train two networks:  \n",
    "1. The **online network**, and  \n",
    "2. The **target network**.  \n",
    "\n",
    "The online network is trained via gradient descent to imitate the target network.  \n",
    "\n",
    "We initialize both networks with the same weights, but the parameters of the target network are frozen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_network = BYOLModel(proj_dim=128).to(device)\n",
    "target_network = BYOLModel(proj_dim=128).to(device)\n",
    "\n",
    "target_network.load_state_dict(copy.deepcopy(online_network.state_dict()))\n",
    "for param in target_network.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: EMA Update\n",
    "\n",
    "Given an initially random target network, after some iterations the potential to learn from it via augmentation-invariant imitation will become saturated. Therefore, we need to update the target network as training progresses.  \n",
    "\n",
    "In BYOL, this is achieved by updating the weights of the target network as an exponential moving average (EMA) of the online network after every optimization step. For each weight $w$ and update rate $\\beta$, the update is given by:  \n",
    "$$\n",
    "w_{\\mathrm{target}} = \\beta \\, w_{\\mathrm{target}} + (1 - \\beta) \\, w_{\\mathrm{online}}\n",
    "$$\n",
    "\n",
    "Implement this update rule in the `update` function of the following helper object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA():\n",
    "\n",
    "    def __init__(self, beta=0.99):\n",
    "        self.beta = beta\n",
    "    \n",
    "    def update(self, online, target):\n",
    "        \"\"\"\n",
    "        Update target network parameters (inplace) using exponential moving average of online network parameters.\n",
    "        online: online network (nn.Module)\n",
    "        target: target network (nn.Module)\n",
    "        \"\"\"\n",
    "        for online_param, target_param in zip(online.parameters(), target.parameters()):\n",
    "            target_param.data = self.beta * target_param.data + (1 - self.beta) * online_param.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: BYOL Training\n",
    "\n",
    "In the BYOL training loss, the **normalized predictions** of the online network are compared against the **normalized projections** of the target network. See the illustration below. \n",
    "\n",
    "![BYOL Diagram](https://raw.githubusercontent.com/lucidrains/byol-pytorch/master/diagram.png)\n",
    "\n",
    "For an image $x$ and transformations $t, t'$, the loss $\\mathcal{L}_{BYOL}(x,t,t')$ computes as \n",
    "$$\n",
    "\\mathcal{L}_{BYOL}(x,t,t') \n",
    "= \\left\\| \\frac{q_{\\theta}(z^{(1)})}{\\|q_{\\theta}(z^{(1)})\\|_2} - \\frac{\\text{sg}(z^{(2)})}{\\|\\text{sg}(z^{(2)})\\|_2} \\right\\|_2^2\n",
    "= 2 - 2 \\cdot \\frac{\\langle q_{\\theta}(z^{(1)}), \\; \\text{sg}(z^{(2)}) \\rangle}{\\| q_{\\theta}(z^{(1)}) \\|_2 \\, \\| \\text{sg}(z^{(2)}) \\|_2}\n",
    "$$\n",
    "where $z^{(1)}$ is the projection of $t(x)$ under the student network and $z^{(2)}$ is the projection of $t'(x)$ under the teacher network.\n",
    "\n",
    "The total loss for a batch $\\{x_i\\}_{i=1}^{N}$ reads\n",
    "$$\n",
    "\\mathcal{L}_{BYOL} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathcal{L}_{BYOL}(x,t,t') + \\mathcal{L}_{BYOL}(x,t',t). \n",
    "$$\n",
    "\n",
    "Complete and run the provided training below accordingly.\\\n",
    "*Hint: Don't be surprised if with the provided configuration the model takes a bit longer to converge than SimCLR.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 50\n",
    "\n",
    "ema = EMA(beta=0.99)\n",
    "\n",
    "optimizer = torch.optim.AdamW(online_network.parameters(), lr=0.5, weight_decay=1e-6)\n",
    "\n",
    "\n",
    "all_accuracies = []\n",
    "all_losses = []\n",
    "for epoch in range(total_epochs):\n",
    "    avg_loss = 0.\n",
    "    online_network.train()\n",
    "    for x1, x2, y in tqdm(train_loader):\n",
    "        # TODO\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "        _, _, pred_online = online_network(torch.concat([x1, x2], dim=0))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, proj_target, _ = target_network(torch.concat([x2, x1], dim=0))\n",
    "        \n",
    "        byol_loss = 2 - 2 * (pred_online * proj_target.detach()).sum(dim=-1)\n",
    "        byol_loss = byol_loss.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        byol_loss.backward()\n",
    "        avg_loss += byol_loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        ema.update(online_network, target_network)\n",
    "\n",
    "    online_network.eval()\n",
    "    train_features, train_labels = extract_features_and_labels(online_network, train_loader_noaugment, normalize=True)\n",
    "    test_features, test_labels = extract_features_and_labels(online_network, test_loader_noaugment, normalize=True)\n",
    "    acc = run_knn_probe(train_features, train_labels, test_features, test_labels)\n",
    "    avg_loss = avg_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}, kNN Accuracy: {acc}\")\n",
    "    all_accuracies.append(acc)\n",
    "    all_losses.append(avg_loss)\n",
    "\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "torch.save(online_network.state_dict(), f'./checkpoints/byol_cifar10.pth')\n",
    "print('Model saved to ./checkpoints/byol_cifar10.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss and accuracy curves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(range(1, total_epochs+1), all_losses)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Average BYOL Loss')\n",
    "\n",
    "axes[1].plot(range(1, total_epochs+1), all_accuracies)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('k-NN Accuracy (%)')\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also run a quick linear probe for the final results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features_and_labels(online_network, train_loader_noaugment, normalize=True)\n",
    "test_features, test_labels = extract_features_and_labels(online_network, test_loader_noaugment, normalize=True)\n",
    "\n",
    "acc = run_linear_probe(train_features, train_labels, test_features, test_labels)\n",
    "print(f'Final Linear Probe Accuracy: {acc:.4f}%')\n",
    "print(f'Final k-NN Accuracy: {all_accuracies[-1]:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: On the Role of the Predicor Head\n",
    "\n",
    "The asymmetry in the BYOL lossâ€”i.e., that the prediction from one view is matched to the projection of the other viewâ€”is an important feature of the BYOL architecture.  \n",
    "\n",
    "**Discussion:** What could be the role of this asymmetry?  \n",
    "\n",
    "*Hint:* Consider what would happen without the predictor. What would be a local minimum of the loss in that case?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** The predictor helps to avoid collapse,  where the model learns to predict a constant representation. This is otherwise a common issue in self-supervised learning based on alignment with out negative examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Barlow Twins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us implement **Barlow Twins**. Similar to BYOL, it is a self-supervised learning method that aligns representations of different views of the same images without using negative examples.  \n",
    "\n",
    "However, it uses only a single network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentations and Architecture\n",
    "\n",
    "We provide the transformation as well as a model architecture which is very similiar to that of SimCLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwinsTransform:\n",
    "\n",
    "    def __init__(self, size=32, s=0.5, blur_p=0.5):\n",
    "        color_jitter = T.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "        k = 3 if size <= 32 else 5\n",
    "        base = [\n",
    "            T.RandomResizedCrop(size=size, scale=(0.2, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomApply([color_jitter], p=0.8),\n",
    "            T.RandomGrayscale(p=0.2),\n",
    "            T.RandomApply([T.GaussianBlur(kernel_size=k, sigma=(0.1, 2.0))], p=blur_p),\n",
    "            T.ToTensor()\n",
    "        ]\n",
    "        self.train_transform = T.Compose(base)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.train_transform(x), self.train_transform(x)\n",
    "\n",
    "\n",
    "def barlowtwins_collate_fn(batch):\n",
    "    xs1, xs2, ys = [], [], []\n",
    "    for (x1, x2), y in batch:\n",
    "        xs1.append(x1)\n",
    "        xs2.append(x2)\n",
    "        ys.append(y)\n",
    "    return torch.stack(xs1), torch.stack(xs2), torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwinsModel(nn.Module):\n",
    "\n",
    "    def __init__(self, proj_dim=128, hidden_dim=2048):\n",
    "        super().__init__()\n",
    "        enc = resnet18(weights=None)\n",
    "        enc.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        enc.maxpool = nn.Identity()\n",
    "        enc.fc = nn.Identity()\n",
    "        self.encoder = enc\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(512, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, proj_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = self.encoder(x)\n",
    "        proj = self.projector(repr)\n",
    "\n",
    "        return repr, proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Barlow Twins Loss\n",
    "\n",
    "Let $z_1, z_2 \\in \\mathbb{R}^{N\\times d}$ be the projected representations of the same images $x$ under different augmentations. The Barlow Twins loss is defined as follows:\n",
    "\n",
    "Let $\\bar{z}_1, \\bar{z}_2$ be the batch-normalized projected representations (i.e., zero mean and unit standard deviation along the batch dimension), and let $\\mathcal{C}$ be the resulting normalized cross-correlation matrix:  \n",
    "$$\n",
    "\\mathcal{C} = \\frac{\\bar{z}_1^T \\bar{z}_2}{N}\n",
    "$$\n",
    "\n",
    "The Barlow Twins loss is given by:  \n",
    "$$\n",
    "\\mathcal{L}_{BT} = \\sum_{i=1}^{d} \\left( 1 - \\mathcal{C}_{ii} \\right)^2 \\;+\\; \\alpha \\sum_{i=1}^{d} \\sum_{j \\neq i} \\mathcal{C}_{ij}^2\n",
    "$$\n",
    "where $\\alpha$ is a trade-off factor.  \n",
    "\n",
    "**Questions:**  \n",
    "1. Hypothesize the role of the two terms in the loss function.  \n",
    "2. How does this loss avoid collapse to a trivial representation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "**Invariance:** $\\sum_i (1 - \\mathcal{C}_{ii})^2$ â€” aligns embeddings of the same image under different augmentations.  \n",
    "**Redundancy reduction:** $\\lambda \\sum_{i} \\sum_{j \\neq i} \\mathcal{C}_{ij}^2$ â€” decorrelates feature dimensions to reduce redundancy.\n",
    "\n",
    "Collapse is avoided by batch normalizing the projected representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the loss function below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_diagonal(x):\n",
    "    bs, d = x.shape\n",
    "    return x.flatten()[:-1].view(bs - 1, bs + 1)[:, 1:].flatten()\n",
    "\n",
    "def barlow_loss(z1, z2, alpha, eps=1e-5):\n",
    "    \"\"\"\n",
    "    z1: (batch_size, feature_dim) tensor of projection vectors\n",
    "    z2: (batch_size, feature_dim) tensor of projection vectors\n",
    "    alpha: redundancy reduction strength (float)\n",
    "    returns: loss (scalar)\n",
    "    \"\"\"\n",
    "    # TODO \n",
    "    B, d = z1.shape\n",
    "    z1 = (z1 - z1.mean(dim=0, keepdim=True)) / torch.sqrt(z1.var(dim=0, keepdim=True) + eps) # (B, d)\n",
    "    z2 = (z2 - z2.mean(dim=0, keepdim=True)) / torch.sqrt(z2.var(dim=0, keepdim=True) + eps) #\n",
    "\n",
    "    cross_corr = z1.T @ z2 / B\n",
    "\n",
    "    invariance_term = torch.diagonal(cross_corr).add_(-1).pow_(2).sum()\n",
    "    redundancy_term = off_diagonal(cross_corr).pow_(2).sum()\n",
    "\n",
    "    loss = invariance_term + alpha * redundancy_term\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize datasets and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barlowtwins_transform = BarlowTwinsTransform(size=32)\n",
    "\n",
    "train_ds = CIFAR10(root=\"./data\", train=True, download=True, transform=barlowtwins_transform)\n",
    "test_ds  = CIFAR10(root=\"./data\", train=False, download=True, transform=barlowtwins_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=256, num_workers=10, pin_memory=True, collate_fn=barlowtwins_collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=256, num_workers=10, pin_memory=True, collate_fn=barlowtwins_collate_fn)\n",
    "\n",
    "train_ds_noaugment = CIFAR10(root=\"./data\", train=True, download=True, transform=default_transform)\n",
    "test_ds_noaugment  = CIFAR10(root=\"./data\", train=False, download=True, transform=default_transform)\n",
    "\n",
    "train_loader_noaugment = DataLoader(train_ds_noaugment, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader_noaugment  = DataLoader(test_ds_noaugment,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barlow_model = BarlowTwinsModel(proj_dim=128).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Barlow Twins Training\n",
    "\n",
    "Complete the training pipeline below. We suggest $\\alpha = 0.005$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 50\n",
    "\n",
    "optimizer = torch.optim.AdamW(barlow_model.parameters(), lr=0.5, weight_decay=1e-6)\n",
    "\n",
    "all_accuracies = []\n",
    "all_losses = []\n",
    "for epoch in range(total_epochs):\n",
    "    barlow_model.train()\n",
    "    avg_loss = 0.\n",
    "    for x1, x2, y in tqdm(train_loader):\n",
    "        # TODO\n",
    "        x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "        _, proj1 = barlow_model(x1)\n",
    "        _, proj2 = barlow_model(x2)\n",
    "\n",
    "        loss = barlow_loss(proj1, proj2, alpha=0.005)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "    barlow_model.eval()\n",
    "\n",
    "    train_features, train_labels = extract_features_and_labels(barlow_model, train_loader_noaugment, normalize=True)\n",
    "    test_features, test_labels = extract_features_and_labels(barlow_model, test_loader_noaugment, normalize=True)\n",
    "    acc = run_knn_probe(train_features, train_labels, test_features, test_labels)\n",
    "    avg_loss = avg_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, average loss: {avg_loss/len(train_loader):.4f}, kNN accuracy: {acc:.4f}')\n",
    "\n",
    "    all_accuracies.append(acc)\n",
    "    all_losses.append(avg_loss)\n",
    "\n",
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "torch.save(barlow_model.state_dict(), f'./checkpoints/barlowtwins_cifar10.pth')\n",
    "print('Model saved to ./checkpoints/barlowtwins_cifar10.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss and accuracy curves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(range(1, total_epochs+1), all_losses)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Average Barlow Twins Loss')\n",
    "\n",
    "axes[1].plot(range(1, total_epochs+1), all_accuracies)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('k-NN Accuracy (%)')\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the final linear probe accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features_and_labels(barlow_model, train_loader_noaugment, normalize=True)\n",
    "test_features, test_labels = extract_features_and_labels(barlow_model, test_loader_noaugment, normalize=True)\n",
    "\n",
    "acc = run_linear_probe(train_features, train_labels, test_features, test_labels)\n",
    "print(f'Final Linear Probe Accuracy: {acc:.4f}%')\n",
    "print(f'Final k-NN Accuracy: {all_accuracies[-1]:.4f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissuevit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
